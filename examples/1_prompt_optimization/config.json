{
    "settings": [
        {
            "name": "Openai_Inference_Runner",
            "protocol": "tcp",
            "ip": "127.0.0.1",
            "port": "5514",
            "port_logger": "6514",
            "enable_dryrun": "0",
            "debug_output_cli": "1",
            "api_key": "your_api_key",
            "model_name": "gpt-4-1106-preview",
            "max_tokens": "450",
            "temperature": "1.0",
            "top_p": "0.5",
            "frequency_penalty": "0.5"
        }
    ]
}